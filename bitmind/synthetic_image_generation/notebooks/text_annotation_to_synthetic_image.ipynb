{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f92f8b-817e-478b-8b92-18c576bbdcbd",
   "metadata": {},
   "source": [
    "## Text Annotation to Synthetic Image Pipeline\n",
    "\n",
    "This notebook demonstrates using advanced diffusion models to generate synthetic images locally using descriptive text annotations (captions) from BLIp-2 captioning (formatted as JSONs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8078ca99-b6b7-4217-97c5-23ef0667d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import logging\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count, current_process, Manager, get_context\n",
    "\n",
    "# Third-party library imports\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "from transformers import pipeline\n",
    "from diffusers import DiffusionPipeline\n",
    "from diffusers.models.modeling_outputs import Transformer2DModelOutput\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "\n",
    "# Local/application-specific imports\n",
    "import bittensor as bt\n",
    "from bitmind.constants import PROMPT_GENERATOR_NAMES, PROMPT_GENERATOR_ARGS, DIFFUSER_NAMES, DIFFUSER_ARGS\n",
    "from multiprocessing_tasks import worker_initializer, generate_images_for_chunk\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow logging (1: filter out INFO, 2: additionally filter out WARNING, 3: additionally filter out ERROR)\n",
    "import tensorflow as tf  # Import TensorFlow after setting the log level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8cc9c0-1e2d-4995-af7e-3ff9819d3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Suppress FutureWarnings from diffusers module\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='diffusers')\n",
    "# Set device for model operations\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "if device == \"cpu\":\n",
    "    raise RuntimeError(\"This script requires a GPU because it uses torch.float16.\")  # Added check for GPU availability\n",
    "# Ensure that this script uses 'spawn' method for starting multiprocessing tasks\n",
    "ctx = get_context(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db788da4-0457-4dfe-9d2e-2493cd68c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_datasets(base_dir):\n",
    "    \"\"\"List all subdirectories in the base directory.\"\"\"\n",
    "    return [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "def load_annotations(base_dir, dataset):\n",
    "    \"\"\"Load annotations from JSON files within a specified directory.\"\"\"\n",
    "    annotations = []\n",
    "    path = os.path.join(base_dir, dataset)\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            with open(os.path.join(path, filename), 'r') as file:\n",
    "                data = json.load(file)\n",
    "                annotations.append(data)\n",
    "    return annotations\n",
    "\n",
    "def load_diffuser(model_name):\n",
    "    \"\"\"Load a diffusion model by name, configured to provided arguments.\"\"\"\n",
    "    bt.logging.info(f\"Loading image generation model ({model_name})...\")\n",
    "    model = DiffusionPipeline.from_pretrained(\n",
    "        model_name, torch_dtype=torch.float32 if device == \"cpu\" else torch.float16, **DIFFUSER_ARGS[model_name]\n",
    "    )\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db054c-21fe-40e0-b7b0-5ec6270a5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU\n",
    "def generate_images(annotations, diffuser, save_dir, num_images, batch_size, diffuser_name):\n",
    "    \"\"\"Generate images from annotations using a diffuser and save to the specified directory.\"\"\"\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    generated_images = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(min(num_images, len(annotations))):\n",
    "            start_loop = time.time()\n",
    "            annotation = annotations[i]\n",
    "            prompt = annotation['description']\n",
    "            index = annotation.get('index', f\"missing_index\")\n",
    "\n",
    "            logging.info(f\"Annotation {i}: {json.dumps(annotation, indent=2)}\")\n",
    "\n",
    "            generated_image = diffuser(prompt=prompt).images[0]\n",
    "            logging.info(f\"Type of generated image: {type(generated_image)}\")\n",
    "\n",
    "            if isinstance(generated_image, torch.Tensor):\n",
    "                img = ToPILImage()(generated_image)\n",
    "            else:\n",
    "                img = generated_image\n",
    "\n",
    "            safe_prompt = prompt[:50].replace(' ', '_').replace('/', '_').replace('\\\\', '_')\n",
    "            img_filename = f\"{save_dir}/{safe_prompt}-{index}.png\"\n",
    "            img.save(img_filename)\n",
    "            generated_images.append(img_filename)\n",
    "            loop_time = time.time() - start_loop\n",
    "            logging.info(f\"Image saved to {img_filename}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    logging.info(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "    return generated_images\n",
    "\n",
    "\n",
    "def load_and_initialize_diffuser(diffuser_name, previous_diffuser=None):\n",
    "    \"\"\"Load and initialize the diffuser, handling previous diffuser cleanup if needed.\"\"\"\n",
    "    if previous_diffuser is not None:\n",
    "        logging.info(\"Deleting previous diffuser, freeing memory\")\n",
    "        # Move to float32 if it's float16, then move to CPU for deletion\n",
    "        if previous_diffuser.dtype == torch.float16:\n",
    "            previous_diffuser = previous_diffuser.to(dtype=torch.float32)\n",
    "        previous_diffuser.to('cpu')\n",
    "        del previous_diffuser\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return load_diffuser(diffuser_name)\n",
    "\n",
    "def test_diffuser_on_dataset(dataset, annotations, diffuser, output_dir, num_images, batch_size, diffuser_name):\n",
    "    \"\"\"Test a single diffuser on a given dataset.\"\"\"\n",
    "    dataset_name = dataset.rsplit('/', 1)[-1] if '/' in dataset else dataset\n",
    "    diffuser_name = diffuser_name.rsplit('/', 1)[-1] if '/' in diffuser_name else diffuser_name\n",
    "    save_dir = os.path.join(output_dir, dataset_name, diffuser_name)\n",
    "    logging.info(f\"Testing {diffuser_name} on annotation dataset {dataset} at {save_dir}...\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        generate_images(annotations, diffuser, save_dir, num_images, batch_size, diffuser_name)\n",
    "        logging.info(\"Images generated and saved successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to generate images with {diffuser_name}: {str(e)}\")\n",
    "\n",
    "def cleanup_diffuser(diffuser):\n",
    "    \"\"\"Clean up resources associated with a diffuser.\"\"\"\n",
    "    logging.info(\"Deleting diffuser, freeing memory\")\n",
    "    # Move to float32 if it's float16, then move to CPU for deletion\n",
    "    if diffuser.dtype == torch.float16:\n",
    "        diffuser = diffuser.to(dtype=torch.float32)\n",
    "    diffuser.to('cpu')\n",
    "    del diffuser\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def test_diffusers_on_datasets(annotations_dir, output_dir, num_images=1, batch_size=2):\n",
    "    \"\"\"Test various diffusers on datasets.\"\"\"\n",
    "    datasets = list_datasets(annotations_dir)\n",
    "    for diffuser_name in DIFFUSER_NAMES:\n",
    "        logging.info(f\"Loading and initializing diffuser: {diffuser_name}\")\n",
    "        diffuser = load_and_initialize_diffuser(diffuser_name)\n",
    "        for dataset in datasets:\n",
    "            annotations = load_annotations(annotations_dir, dataset)\n",
    "            test_diffuser_on_dataset(dataset, annotations, diffuser, output_dir, num_images, batch_size, diffuser_name)\n",
    "        cleanup_diffuser(diffuser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b99ce-efbc-413b-822b-3234246643db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiprocessing loop\n",
    "def multiprocess_generate_images(annotations_dir, output_dir, num_processes=None):\n",
    "    if num_processes is None:\n",
    "        num_processes = max(1, cpu_count() - 1)  # Leaves one CPU core free\n",
    "\n",
    "    datasets = list_datasets(annotations_dir)\n",
    "    for model_name in DIFFUSER_NAMES:\n",
    "        logging.info(f\"Processing with model: {model_name}\")\n",
    "        with ctx.Pool(processes=num_processes, initializer=worker_initializer, initargs=(model_name, device, DIFFUSER_ARGS)) as pool:\n",
    "            for dataset in datasets:\n",
    "                annotations = load_annotations(annotations_dir, dataset)\n",
    "                save_dir = os.path.join(output_dir, model_name, dataset)\n",
    "\n",
    "                # Split annotations into chunks for each worker\n",
    "                chunk_size = (len(annotations) + num_processes - 1) // num_processes\n",
    "                chunks = [annotations[i:i + chunk_size] for i in range(0, len(annotations), chunk_size)]\n",
    "\n",
    "                results = pool.starmap(generate_images_for_chunk, [(chunk, save_dir) for chunk in chunks])\n",
    "                logging.info(f\"Completed processing for dataset {dataset} with model {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef374c37-335b-457f-aafd-139f00025d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_DIR = \"test_data/annotations/\"\n",
    "OUTPUT_DIR = \"test_data/synthetics_from_annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ed638-42d4-44be-8d46-fb14c04287fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "test_diffusers_on_datasets(ANNOTATIONS_DIR, OUTPUT_DIR, num_images=1, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb4ccf-330f-4982-94cb-c47cd0beb1bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CPU Multiprocessing\n",
    "# multiprocess_generate_images(ANNOTATIONS_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90598c4b-4325-47a0-bf92-d207a79cf7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_specific_diffuser_on_specific_dataset(annotations_dir, output_dir, diffuser_name=\"stabilityai/stable-diffusion-xl-base-1.0\", dataset_name=\"dalle-mini_open-images\", num_images=1, batch_size=8):\n",
    "    \"\"\"Test a specific diffuser on a specific dataset\"\"\"\n",
    "    logging.info(f\"Loading and initializing diffuser: {diffuser_name}\")\n",
    "    diffuser = load_and_initialize_diffuser(diffuser_name)\n",
    "    annotations = load_annotations(annotations_dir, dataset_name)\n",
    "    \n",
    "    logging.info(f\"Testing diffuser: {diffuser_name} on dataset: {dataset_name}\")\n",
    "    test_diffuser_on_dataset(dataset_name, annotations, diffuser, output_dir, num_images, batch_size, diffuser_name)\n",
    "    \n",
    "    cleanup_diffuser(diffuser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2218a909-dc30-4492-99c5-fbe1c6145e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFFUSER_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5c020-9469-4c35-ad95-7a051d031fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_diff = \"stable_test/\"\n",
    "ANNOTATIONS_DIR = \"test_data/dataset/annotations/\"\n",
    "test_specific_diffuser_on_specific_dataset(ANNOTATIONS_DIR, stable_diff, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56669618-bf59-4838-8e07-ae47193ac8a2",
   "metadata": {},
   "source": [
    "Image Comparison Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65bc01-64aa-4a67-a61e-a6225f53fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standard libraries\n",
    "# import random\n",
    "# import logging\n",
    "\n",
    "# # Third-party libraries\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "\n",
    "# # Bitmind-specific libraries\n",
    "# from bitmind.image_dataset import ImageDataset\n",
    "# from bitmind.constants import DATASET_META\n",
    "\n",
    "# # Initialize seeds for reproducibility\n",
    "# torch.manual_seed(0)\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # Suppress logs\n",
    "# transformers_level = logging.getLogger(\"transformers\").getEffectiveLevel()\n",
    "# huggingface_hub_level = logging.getLogger(\"huggingface_hub\").getEffectiveLevel()\n",
    "# logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "# logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "\n",
    "# # Load the processor and model\n",
    "# processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-2.7b-coco\")\n",
    "# model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b-coco\", torch_dtype=torch.float16) \n",
    "# model.to(device)\n",
    "\n",
    "# # Restore log settings\n",
    "# logging.getLogger(\"transformers\").setLevel(transformers_level)\n",
    "# logging.getLogger(\"huggingface_hub\").setLevel(huggingface_hub_level)\n",
    "\n",
    "# # Load real datasets\n",
    "# print(\"Loading real datasets\")\n",
    "# real_image_datasets = [\n",
    "#     ImageDataset(ds['path'], 'test', ds.get('name', None), ds['create_splits'])\n",
    "#     for ds in DATASET_META['real']\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12e3f8-319a-4388-8132-9dfa34d75c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Target dataset name and index of image to display\n",
    "# target_dataset_name = 'dalle-mini/open-images'\n",
    "# index_of_image = 10\n",
    "\n",
    "# for dataset in real_image_datasets:\n",
    "#     if dataset.huggingface_dataset_path == target_dataset_name:\n",
    "#         for index, image_info in enumerate(dataset):\n",
    "#             if index == index_of_image:\n",
    "#                 display(image_info['image'])\n",
    "#                 break\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
