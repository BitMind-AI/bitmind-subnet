{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5214826-521c-43ba-ae33-cc2b4e4296fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "from validate import validate\n",
    "from networks.trainer import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from bitmind.image_transforms import base_transforms, random_aug_transforms\n",
    "from util.data import load_datasets, create_real_fake_datasets\n",
    "from options import TrainOptions\n",
    "\n",
    "\n",
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887887d-d8bd-4034-a394-9bec29b99428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = TrainOptions().parse()\n",
    "seed_torch(100)\n",
    "opt.name = 'aug_rotfirst'\n",
    "\n",
    "#Logger(os.path.join(opt.checkpoints_dir, opt.name, 'log.log'))\n",
    "\n",
    "train_writer = SummaryWriter(os.path.join(opt.checkpoints_dir, opt.name, \"train\"))\n",
    "val_writer = SummaryWriter(os.path.join(opt.checkpoints_dir, opt.name, \"val\"))\n",
    "\n",
    "# RealFakeDataseta will limit the number of images sampled per dataset to the length of the smallest dataset\n",
    "real_datasets, fake_datasets = load_datasets()\n",
    "train_dataset, val_dataset, test_dataset = create_real_fake_datasets(\n",
    "    real_datasets, \n",
    "    fake_datasets, \n",
    "    train_transforms=random_aug_transforms,\n",
    "    val_transforms=base_transforms,\n",
    "    test_transforms=base_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=lambda d: tuple(d))\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False, num_workers=0, collate_fn=lambda d: tuple(d))\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False, num_workers=0, collate_fn=lambda d: tuple(d))\n",
    "\n",
    "# RealFakeDataseta will limit the number of images sampled per dataset to the length of the smallest dataset\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184fda9e-0397-4037-89bf-bfc5177af3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Trainer(opt)\n",
    "\n",
    "display_loss_steps = 10\n",
    "early_stopping_epochs = 10\n",
    "best_val_acc = 0\n",
    "n_epoch_since_improvement = 0\n",
    "model.train()\n",
    "\n",
    "print(f'cwd: {os.getcwd()}')\n",
    "for epoch in range(opt.niter):\n",
    "\n",
    "    for step, data in enumerate(train_loader):\n",
    "        model.set_input(data)\n",
    "        model.optimize_parameters()\n",
    "\n",
    "        if step % display_loss_steps == 0:\n",
    "            ts = time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime())\n",
    "            print(f\"{ts} | Step: {step} ({model.total_steps}) | Train loss: {model.loss} | lr {model.lr}\")\n",
    "\n",
    "        if model.total_steps % opt.loss_freq == 0:\n",
    "            train_writer.add_scalar('loss', model.loss, model.total_steps)\n",
    "                    \n",
    "        model.total_steps += 1\n",
    "\n",
    "    if epoch % opt.delr_freq == 0 and epoch != 0:\n",
    "        ts = time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime())\n",
    "        print(ts, 'changing lr at the end of epoch %d, iters %d' % (epoch, model.total_steps))\n",
    "        model.adjust_learning_rate()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    acc, ap = validate(model.model, val_loader)[:2]\n",
    "    val_writer.add_scalar('accuracy', acc, model.total_steps)\n",
    "    val_writer.add_scalar('ap', ap, model.total_steps)\n",
    "\n",
    "    print(\"(Val @ epoch {}) acc: {}; ap: {}\".format(epoch, acc, ap))\n",
    "    if acc > best_val_acc:\n",
    "        model.save_networks('best')\n",
    "        best_val_acc = acc\n",
    "    else:\n",
    "        n_epoch_since_improvement += 1\n",
    "        if n_epoch_since_improvement >= early_stopping_epochs:\n",
    "            break\n",
    "\n",
    "    model.train()\n",
    "\n",
    "model.eval()\n",
    "acc, ap = validate(model.model, test_loader)[:2]\n",
    "print(\"(Test) acc: {}; ap: {}\".format(acc, ap))\n",
    "model.save_networks('last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be956524-9acf-40aa-996f-abd7ee011bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b903cb-fa08-430d-befd-75a638b6a129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
